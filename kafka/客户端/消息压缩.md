#### 消息格式

Kafka 的消息层次都分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），而日志项才是真正封装消息的地方。Kafka 底层的消息日志由一系列消息集合日志项组成。Kafka 通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。

（上面这段没看太明白，引用作者的回复：）

> 消息批次RecordBatch里面包含若干条消息（record)。
> 你可以认为消息批次和消息集合是等价的，消息和日志项是等价的。
> 这样消息层次有两层：外层是消息批次（或消息集合）；里层是消息（或日志项）。
> Producer以recordbatch为单位发送消息，对于V2版本一个batch中通常包含多条消息。

##### v2 VS v1

把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。

 V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本的做法是对整个消息集合进行压缩。

#### 压缩

在 Kafka 中，压缩可能发生在两个地方：生产者端和 Broker 端。

生产者程序中配置 `compression.type` 参数即表示启用指定类型的压缩算法。

大部分情况下 Broker 从 Producer 端接收到消息后仅仅是原封不动地保存而不会对其进行任何修改，但有两种例外情况：

情况一：Broker 端指定了和 Producer 端不同的压缩算法。

Broker 端也有一个参数叫 compression.type。

情况二：Broker 端发生了消息格式转换。

#### 解压缩

通常来说解压缩发生在消费者程序中。

Kafka 会将启用了哪种压缩算法封装进消息集合中，这样当 Consumer 读取到消息集合时，它自然就知道了这些消息使用的是哪种压缩算法。

除了在 Consumer 端解压缩，Broker 端也会进行解压缩，但是这里的解压缩仅仅是为了对消息执行各种验证。

**总结**：Producer 端压缩、Broker 端保持、Consumer 端解压缩。

#### 压缩算法对比

在 Kafka 2.1.0 版本之前，Kafka 支持 3 种压缩算法：GZIP、Snappy 和 LZ4。

从 2.1.0 开始，Kafka 正式支持 Zstandard 算法（简写为 zstd）。它是 Facebook 开源的一个压缩算法，能够提供超高的压缩比（compression ratio）。

![img](/Users/tianzhiwei/Code/kafka/learn-kafka/images/cfe20a2cdcb1ae3b304777f7be928068.png)

在吞吐量方面：LZ4 > Snappy > zstd 和 GZIP；而在压缩比方面，zstd > LZ4 > GZIP > Snappy。

在 CPU 使用率方面，各个算法表现得差不多，只是在压缩时 Snappy 算法使用的 CPU 较多一些，而在解压缩时 GZIP 算法则可能使用更多的 CPU。

#### 最佳实践

启用压缩的一个条件就是 Producer 程序运行机器上的 CPU 资源要很充足。

除了 CPU 资源充足这一条件，如果你的环境中带宽资源有限，那么我也建议你开启压缩。

#### 其它

消息（v1叫message，v2叫record）是分批次（batch）读写的，batch是kafka读写（网络传输和文件读写）的基本单位。

目前java consumer的设计是一次取出一批，缓存在客户端内存中，然后再过滤出max.poll.records条消息返给你，也不算太浪费吧，毕竟下次可以直接从缓存中取，不用再发请求了。

在 Producer 端即使消息并没有达到 batch.size 的数量，`linger.ms` 也可以让它发送一批数据。如果是生产了一条消息且linger.ms=0，通常producer就会立即发送者一条消息了。



