新版本 Consumer 的位移管理机制其实也很简单，就是**将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 \_\_consumer_offsets 中。可以这么说，\_\_consumer_offsets 的主要作用是保存 Kafka 消费者的位移信息。**

##### 消息格式

位移主题的 Key 中应该保存 3 部分内容：<Group ID，主题名，分区号 >。

消息体保存了位移提交的一些其他元数据，诸如时间戳和用户自定义的数据等。保存这些元数据是为了帮助 Kafka 执行各种各样后续的操作，比如删除过期位移消息等。

位移主题的消息格式还有其它 2 种格式：

1. 用于保存 Consumer Group 信息的消息。

2. 用于删除 Group 过期位移甚至是删除 Group 的消息。

##### 主题

位移主题的分区数是怎么设置的呢？这就要看 Broker 端参数 `offsets.topic.num.partitions` 的取值了。它的默认值是 50，因此 Kafka 会自动创建一个 50 分区的位移主题。

除了分区数，副本数或备份因子是怎么控制的呢？答案也很简单，这就是 Broker 端另一个参数 `offsets.topic.replication.factor` 要做的事情了。它的默认值是 3。

##### 提交位移

Consumer 端有个参数叫 enable.auto.commit，如果值是 true，则 Consumer 在后台默默地为你定期提交位移，提交间隔由一个专属的参数 auto.commit.interval.ms 来控制。自动提交位移有一个显著的优点，就是省事，你不用操心位移提交的事情，就能保证消息消费不会丢失。但这一点同时也是缺点。因为它太省事了，以至于丧失了很大的灵活性和可控性，你完全没法把控 Consumer 端的位移管理。

##### 过期消息整理

Kafka 使用 **Compact 策略** 来删除位移主题中的过期消息，避免该主题无限期膨胀。那么应该如何定义 Compact 策略中的过期呢？对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。

