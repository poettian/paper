#### 查看配置

使用 `kafka-configs.sh`

```bash
bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name my-topic --describe
```

#### Broker 端参数

很重要的一点，关于参数是静态（需要重启broker）还是动态，读取顺序和优先级：

参考：[Updating Broker Configs](https://kafka.apache.org/documentation/#dynamicbrokerconfigs)

##### 信息存储

`log.dirs`

信息存储路径，建议配置多个，且挂载到不同的磁盘，增加吞吐量、实现故障转移。

##### zookeeper

`zookeeper.connect`

zookeeper 集群连接，可以使用 `chroot` 别名：**zk1:2181,zk2:2181,zk3:2181/kafka1**。

##### broker 连接参数

`listeners`

broker 监听地址和端口（注意要把使用的协议带上：比如 `PLAINTEXT://your.host.name:9092`）

`advertised.listeners`

对外公布的地址和端口

**这两个参数啥区别？**

> advertised.listeners主要是为外网访问用的。如果clients在内网环境访问Kafka不需要配置这个参数。
>
> 常见的玩法是：你的Kafka Broker机器上配置了双网卡，一块网卡用于内网访问（即我们常说的内网IP）；另一个块用于外网访问。那么你可以配置listeners为内网IP，advertised.listeners为外网IP。

##### topic 管理

`auto.create.topics.enable`

是否允许自动创建 Topic，建议设为 false

`unclean.leader.election.enable`

是否允许 Unclean Leader 选举，建议设为 false

`auto.leader.rebalance.enable`

是否允许定期进行 Leader 重选举，建议设为 false

##### 数据留存

**A segment will be deleted whenever *either* of these criteria are met. Deletion always happens from the end of the log.**

`log.retention.{hours|minutes|ms}`

控制一条消息数据被保存多长时间

`log.retention.bytes`

指定 Broker 为消息保存的总磁盘容量大小

`log.segment.bytes`

日志段文件的大小，当一个日志段文件大小达到上限时会自动新创建一个

`log.retention.check.interval.ms`

检查周期

##### 消息

`message.max.bytes`

控制 Broker 能够接收的最大消息大小，默认 1000012 有点小。

#### Topic 参数

Configurations pertinent to topics have both a server default as well an optional per-topic override. If no per-topic configuration is given the server default is used. The override can be set at topic creation time by giving one or more `--config` options. 

`min.insync.replicas`

默认值 1

当producer将ack设置为“全部”（或“-1”）时，min.insync.replicas指定了被认为写入成功的最小副本数。

`retention.ms`

消息保存时间，If set to -1, no time limit is applied.

`retention.bytes`

要为该 Topic 预留多大的磁盘空间。

`max.message.bytes`

修改 Topic 级 max.message.bytes，还要考虑以下两点：
还要修改 Broker的 replica.fetch.max.bytes 保证复制正常
消费还要修改配置 fetch.message.max.bytes

#### jvm 参数

`Heap Size`

jvm 堆大小，建议设为 6 GB

设置方法（设定环境变量）：

KAFKA_HEAP_OPTS：指定堆大小

KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。

```bash

$> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g
$> export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true
$> bin/kafka-server-start.sh config/server.properties
```

#### librdkafka 参数（注意以下列出的都是客户端参数）

##### 全局参数

`metadata.broker.list`

broker list，也可以调用方法来指定

`group.id`

消费者组 id

`socket.timeout.ms`

Default timeout for network requests. 

Producer: ProduceRequests will use the lesser value of `socket.timeout.ms` and remaining `message.timeout.ms` for the first message in the batch. 

Consumer: FetchRequests will use `fetch.wait.max.ms` + `socket.timeout.ms`.

 Admin: Admin requests will use `socket.timeout.ms` or explicitly set `rd_kafka_AdminOptions_set_operation_timeout()`

`session.timeout.ms`

consumer 客户端会定时发送心跳信息，If no hearts are received by the broker for a group member within the session timeout, the broker will remove the consumer from the group and trigger a rebalance. 

`max.poll.interval.ms`

high-level consumers

消费消息的最大时间间隔，超过这个间隔会导致 rebalance

`enable.auto.commit`

是否开启自动提交 offset

`auto.commit.interval.ms`

high-level consumer

自动提交 offset 的时间间隔

`enable.auto.offset.store`

是否在内存中自动存储下一次需要提交的 offset

`queue.buffering.max.ms`

producer queue 等待批量发送到 broker 的时间。值越短，消息越快的发送。默认值 0.5， 已经很小了。

`enable.idempotence`

是否启动幂等，精确一次性语义相关参数，没看太懂。

##### topic 参数

`auto.offset.reset`

定义 **broker 端没有保存消费位移 或者 consumer 提供的消费位移在broker中不存在时** cosumer 读取消息的位置。

smallest/earliest - 从开头开始读取

**largest**/latest - 从尾部开始读取（阻塞直到有新消息）

error - 报错，使用 `message->err` 检查错误信息

`request.required.acks`

设定 leader 副本收到复制数据完毕响应的  follower 副本 的数量。

0 - broker 不发送响应给 客户端

**-1**/all - 大于等于 `min.insync.replicas` (broker 端参数)时认为写入成功，否则报错。

其它数量 - 

`partitioner`

根据消息的key，把消息写入不同分区的分配机制

`enable.auto.commit`

DEPRECATED，LEGACY PROPERTY，simple legacy consumer only

控制是否自动提交 offset

`auto.commit.interval.ms`

DEPRECATED，LEGACY PROPERTY，simple legacy consumer only

自动提交 offset 的周期

`offset.store.method` `offset.store.path` `offset.store.sync.interval.ms`

DEPRECATED

控制 offset 存储方式

**注意**：File-based offset storage will be removed in a future version.





